name: Performance Benchmarks

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  # Allow manual triggers
  workflow_dispatch:
    inputs:
      full_suite:
        description: 'Run full benchmark suite'
        required: false
        default: 'false'
        type: boolean

# Ensure only one benchmark runs at a time per branch
concurrency:
  group: benchmark-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Determine what files changed to decide if we need to run benchmarks
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.filter.outputs.benchmark }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Check for relevant changes
        uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            benchmark:
              - 'packages/**/*.ts'
              - 'plugins/**/*.ts'
              - 'benchmarks/**'
              - 'package.json'
              - 'package-lock.json'
              - 'tsconfig*.json'
              - 'tsup.config.ts'

      - name: Skip notification
        if: steps.filter.outputs.benchmark != 'true' && github.event_name == 'pull_request'
        run: |
          echo "### â­ï¸ Benchmarks Skipped" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "No benchmark-relevant changes detected. Skipping benchmarks." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Benchmarks run when changes are made to:" >> $GITHUB_STEP_SUMMARY
          echo "- \`packages/**/*.ts\` - Core package source" >> $GITHUB_STEP_SUMMARY
          echo "- \`plugins/**/*.ts\` - Plugin source" >> $GITHUB_STEP_SUMMARY
          echo "- \`benchmarks/**\` - Benchmark code" >> $GITHUB_STEP_SUMMARY
          echo "- Package config files" >> $GITHUB_STEP_SUMMARY

  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    needs: changes
    # Run if: benchmark-relevant changes detected, OR push to main, OR manual trigger
    if: |
      needs.changes.outputs.should_run == 'true' ||
      github.event_name == 'push' ||
      github.event_name == 'workflow_dispatch'
    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v6
        with:
          fetch-depth: 0 # Full history for comparisons

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20.x
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build packages
        run: npm run build

      # For PRs: Get base branch info
      - name: Get base branch
        if: github.event_name == 'pull_request'
        id: base
        run: |
          echo "ref=${{ github.event.pull_request.base.ref }}" >> $GITHUB_OUTPUT
          echo "sha=${{ github.event.pull_request.base.sha }}" >> $GITHUB_OUTPUT

      # Run current branch benchmarks first
      - name: Run current branch benchmarks
        id: current_benchmark
        run: |
          echo "Running benchmarks on current branch..."
          npx ts-node benchmarks/comparative/cli.ts --quick --no-history --threshold 15

          # Save results for comparison
          mkdir -p .benchmark-results/current
          if [ -d "benchmarks/reports" ]; then
            # Find the latest JSON report
            latest_json=$(ls -t benchmarks/reports/*.json 2>/dev/null | head -1)
            if [ -n "$latest_json" ]; then
              cp "$latest_json" .benchmark-results/current/results.json
              echo "results_available=true" >> $GITHUB_OUTPUT
            else
              echo "results_available=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "results_available=false" >> $GITHUB_OUTPUT
          fi
        env:
          CI: true
          GITHUB_SHA: ${{ github.sha }}
          GITHUB_REF_NAME: ${{ github.head_ref || github.ref_name }}

      # For PRs: checkout base branch and run benchmarks on same runner
      - name: Checkout base branch for comparison
        if: github.event_name == 'pull_request' && steps.current_benchmark.outputs.results_available == 'true'
        run: |
          # Save current benchmark results
          cp -r .benchmark-results/current /tmp/current-benchmarks

          # Checkout base branch
          git checkout ${{ steps.base.outputs.sha }}

      - name: Install base branch dependencies
        if: github.event_name == 'pull_request' && steps.current_benchmark.outputs.results_available == 'true'
        run: npm ci

      - name: Build base branch
        if: github.event_name == 'pull_request' && steps.current_benchmark.outputs.results_available == 'true'
        run: npm run build

      - name: Run base branch benchmarks
        if: github.event_name == 'pull_request' && steps.current_benchmark.outputs.results_available == 'true'
        id: base_benchmark
        run: |
          echo "Running benchmarks on base branch..."
          npx ts-node benchmarks/comparative/cli.ts --quick --no-history --threshold 15

          # Save results for comparison
          mkdir -p .benchmark-results/base
          if [ -d "benchmarks/reports" ]; then
            latest_json=$(ls -t benchmarks/reports/*.json 2>/dev/null | head -1)
            if [ -n "$latest_json" ]; then
              cp "$latest_json" .benchmark-results/base/results.json
              echo "base_available=true" >> $GITHUB_OUTPUT
            else
              echo "base_available=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "base_available=false" >> $GITHUB_OUTPUT
          fi
        env:
          CI: false  # Don't fail on regression against history
          GITHUB_SHA: ${{ steps.base.outputs.sha }}
          GITHUB_REF_NAME: ${{ steps.base.outputs.ref }}

      - name: Restore current branch
        if: github.event_name == 'pull_request' && steps.current_benchmark.outputs.results_available == 'true'
        run: |
          # Checkout back to PR branch
          git checkout ${{ github.event.pull_request.head.sha }}

          # Restore current benchmark results
          mkdir -p .benchmark-results/current
          cp -r /tmp/current-benchmarks/* .benchmark-results/current/

          # Copy base results if available
          if [ -d ".benchmark-results/base" ]; then
            cp -r .benchmark-results/base /tmp/base-benchmarks
          fi

          # Reinstall to get the comparison scripts
          npm ci

      - name: Compare benchmarks (PR - same runner)
        if: github.event_name == 'pull_request' && steps.current_benchmark.outputs.results_available == 'true' && steps.base_benchmark.outputs.base_available == 'true'
        id: compare
        run: |
          # Restore base results
          mkdir -p .benchmark-results/base
          if [ -d "/tmp/base-benchmarks" ]; then
            cp -r /tmp/base-benchmarks/* .benchmark-results/base/
          fi

          # Run comparison with same-runner mode
          npx ts-node benchmarks/comparative/cli.ts \
            --quick \
            --compare-baseline .benchmark-results/base/results.json \
            --current-results .benchmark-results/current/results.json \
            --threshold 15 \
            2>&1 | tee comparison-output.txt

          exit_code=${PIPESTATUS[0]}

          if [ $exit_code -eq 0 ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "regression_detected=false" >> $GITHUB_OUTPUT
          else
            echo "status=regression" >> $GITHUB_OUTPUT
            echo "regression_detected=true" >> $GITHUB_OUTPUT
          fi

          # Don't fail the step - we report in the summary
          exit 0
        env:
          CI: true
          GITHUB_SHA: ${{ github.sha }}
          GITHUB_REF_NAME: ${{ github.head_ref || github.ref_name }}

      # For pushes to main: run full benchmarks and save to history
      - name: Run full benchmarks (main branch)
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        run: |
          npx ts-node benchmarks/comparative/cli.ts \
            ${{ github.event.inputs.full_suite == 'true' && '--full' || '--quick' }} \
            --save-history
        env:
          CI: true
          GITHUB_SHA: ${{ github.sha }}
          GITHUB_REF_NAME: ${{ github.ref_name }}

      - name: Generate GitHub summary
        if: always()
        run: |
          if [ -f "comparison-output.txt" ]; then
            echo '## Performance Comparison Report' >> $GITHUB_STEP_SUMMARY
            echo '' >> $GITHUB_STEP_SUMMARY
            echo '> Benchmarks run on the **same runner** to ensure accurate comparison.' >> $GITHUB_STEP_SUMMARY
            echo '' >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat comparison-output.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          elif [ -d "benchmarks/reports" ]; then
            latest_md=$(ls -t benchmarks/reports/*.md 2>/dev/null | head -1)
            if [ -n "$latest_md" ]; then
              cat "$latest_md" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.sha }}
          path: |
            benchmarks/reports/
            benchmarks/history/
            .benchmark-results/
            comparison-output.txt
          retention-days: 30

      - name: Comment PR with benchmark results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            let body = '## ðŸ“Š Benchmark Results\n\n';
            body += '> Benchmarks run on the **same runner** to ensure accurate comparison.\n\n';

            // First try to read comparison output
            if (fs.existsSync('comparison-output.txt')) {
              const output = fs.readFileSync('comparison-output.txt', 'utf-8');
              body += '```\n' + output + '\n```';
            } else {
              // Fall back to markdown report
              const reportsDir = 'benchmarks/reports';
              if (fs.existsSync(reportsDir)) {
                const files = fs.readdirSync(reportsDir)
                  .filter(f => f.endsWith('.md'))
                  .sort()
                  .reverse();

                if (files.length > 0) {
                  const reportPath = path.join(reportsDir, files[0]);
                  let reportContent = fs.readFileSync(reportPath, 'utf-8');

                  const maxLength = 60000;
                  if (reportContent.length > maxLength) {
                    reportContent = reportContent.substring(0, maxLength) + '\n\n*Report truncated...*';
                  }
                  body = `## ðŸ“Š Benchmark Results\n\n${reportContent}`;
                }
              }
            }

            // Check for existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' &&
              c.body.includes('Benchmark Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body,
              });
            }

      - name: Check regression status
        if: github.event_name == 'pull_request' && steps.compare.outputs.regression_detected == 'true'
        run: |
          echo "::warning::Performance regressions detected. Please review the benchmark report."
          # Optionally fail the build:
          # exit 1

  # Store benchmark history in a separate branch (optional)
  store-history:
    name: Store Benchmark History
    needs: [changes, benchmark]
    runs-on: ubuntu-latest
    if: |
      always() &&
      needs.benchmark.result == 'success' &&
      github.event_name == 'push' &&
      (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    permissions:
      contents: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v6
        with:
          ref: gh-pages
          fetch-depth: 0

      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results-${{ github.sha }}
          path: benchmark-data

      - name: Update benchmark data
        run: |
          mkdir -p benchmarks
          if [ -d "benchmark-data/history" ]; then
            cp -r benchmark-data/history/* benchmarks/ 2>/dev/null || true
          fi
          if [ -d "benchmark-data/reports" ]; then
            mkdir -p reports
            cp -r benchmark-data/reports/* reports/ 2>/dev/null || true
          fi

      - name: Commit and push
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add benchmarks/ reports/ 2>/dev/null || true
          git diff --staged --quiet || git commit -m "Update benchmark data for ${{ github.sha }}"
          git push origin gh-pages || echo "No changes to push"
        continue-on-error: true

  # Generate and deploy the visualization dashboard
  deploy-dashboard:
    name: Deploy Dashboard
    needs: [changes, benchmark]
    runs-on: ubuntu-latest
    if: |
      always() &&
      needs.benchmark.result == 'success' &&
      github.event_name == 'push' &&
      (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    permissions:
      contents: write
      pages: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results-${{ github.sha }}
          path: benchmark-data

      - name: Copy HTML report to dashboard
        run: |
          mkdir -p dashboard
          if [ -d "benchmark-data/reports" ]; then
            # Find latest HTML report
            latest_html=$(ls -t benchmark-data/reports/*.html 2>/dev/null | head -1)
            if [ -n "$latest_html" ]; then
              cp "$latest_html" dashboard/index.html
            fi
          fi
          # Copy history data for the dashboard
          if [ -d "benchmark-data/history" ]; then
            cp -r benchmark-data/history dashboard/
          fi

      - name: Deploy to GitHub Pages
        if: hashFiles('dashboard/index.html') != ''
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./dashboard
          destination_dir: benchmarks
